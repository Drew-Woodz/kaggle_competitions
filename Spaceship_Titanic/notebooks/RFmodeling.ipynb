{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a952aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8693, 34)\n",
      "Test shape: (4277, 33)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reload the baseline cleaned data\n",
    "train = pd.read_csv('../data/train_clean.csv')\n",
    "test = pd.read_csv('../data/test_clean.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba0fb2",
   "metadata": {},
   "source": [
    "**Random Forest Classifier (Baseline)**\n",
    "\n",
    ">Let’s train a Random Forest model on the same data setup used for LightGBM.\n",
    "This will give us a baseline to compare model types before tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5bf5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Log Loss: 0.43776 | Accuracy: 0.7798\n",
      "Fold 2 Log Loss: 0.46023 | Accuracy: 0.7660\n",
      "Fold 3 Log Loss: 0.44062 | Accuracy: 0.7798\n",
      "Fold 4 Log Loss: 0.43780 | Accuracy: 0.7768\n",
      "Fold 5 Log Loss: 0.45675 | Accuracy: 0.7727\n",
      "\n",
      "Overall CV Log Loss: 0.44663\n",
      "Overall CV Accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Reuse X, y setup from earlier (if needed, redefine here)\n",
    "X = train.drop(columns=['Transported'])\n",
    "y = train['Transported'].astype(int)\n",
    "\n",
    "# One-hot encode categorical features (RF doesn’t need label encoding)\n",
    "X = pd.get_dummies(X)\n",
    "test_encoded = pd.get_dummies(test)\n",
    "\n",
    "# Align test features to train\n",
    "test_encoded = test_encoded.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(test_encoded))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_preds += model.predict_proba(test_encoded)[:, 1] / cv.n_splits\n",
    "\n",
    "    logloss = log_loss(y_val, oof_preds[val_idx])\n",
    "    acc = accuracy_score(y_val, oof_preds[val_idx] > 0.5)\n",
    "    print(f\"Fold {fold+1} Log Loss: {logloss:.5f} | Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Final CV scores\n",
    "print(f\"\\nOverall CV Log Loss: {log_loss(y, oof_preds):.5f}\")\n",
    "print(f\"Overall CV Accuracy: {accuracy_score(y, oof_preds > 0.5):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
