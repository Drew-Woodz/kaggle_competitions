{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b56d36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Device: cuda\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0623af",
   "metadata": {},
   "source": [
    "**Data Cleaning & Modeling Pipeline Plan**\n",
    "\n",
    "1. Load and inspect data\n",
    "\n",
    "2. Handle missing values\n",
    "\n",
    "3. Feature engineering\n",
    "\n",
    "4. Encode target\n",
    "\n",
    "5. Train/test split\n",
    "\n",
    "6. Baseline model\n",
    "\n",
    "7. Evaluate and iterate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde67448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (18524, 9)\n",
      "Test shape: (6175, 8)\n",
      "\n",
      "Train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18524 entries, 0 to 18523\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         18524 non-null  int64  \n",
      " 1   Time_spent_Alone           17334 non-null  float64\n",
      " 2   Stage_fear                 16631 non-null  object \n",
      " 3   Social_event_attendance    17344 non-null  float64\n",
      " 4   Going_outside              17058 non-null  float64\n",
      " 5   Drained_after_socializing  17375 non-null  object \n",
      " 6   Friends_circle_size        17470 non-null  float64\n",
      " 7   Post_frequency             17260 non-null  float64\n",
      " 8   Personality                18524 non-null  object \n",
      "dtypes: float64(5), int64(1), object(3)\n",
      "memory usage: 1.3+ MB\n",
      "\n",
      "Missing values in train:\n",
      "Stage_fear                   1893\n",
      "Going_outside                1466\n",
      "Post_frequency               1264\n",
      "Time_spent_Alone             1190\n",
      "Social_event_attendance      1180\n",
      "Drained_after_socializing    1149\n",
      "Friends_circle_size          1054\n",
      "dtype: int64\n",
      "\n",
      "Target value counts:\n",
      "Personality\n",
      "Extrovert    13699\n",
      "Introvert     4825\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and inspect the data\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# Basic overview\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(\"\\nTrain info:\")\n",
    "train.info()\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing values in train:\")\n",
    "print(train.isna().sum()[train.isna().sum() > 0].sort_values(ascending=False))\n",
    "\n",
    "# Preview target\n",
    "print(\"\\nTarget value counts:\")\n",
    "print(train['Personality'].value_counts(dropna=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c8636",
   "metadata": {},
   "source": [
    "**Dataset Summary**\n",
    "**Shapes:**\n",
    "\n",
    "    train: 18,524 rows, 9 columns\n",
    "\n",
    "    test: 6,175 rows, 8 columns (no target)\n",
    "\n",
    "|Column|Missing|Type|\n",
    "|--|--|--|\n",
    "|`Stage_fear`|1,893|object|\n",
    "|`Going_outside`|1,466|float|\n",
    "|`Post_frequency`|1,264|float|\n",
    "|`Time_spent_Alone`|1,190|float|\n",
    "|`Social_event_attendance`|1,180|float|\n",
    "|`Drained_after_socializing`|1,149|object|\n",
    "|`Friends_circle_size`|1,054|float|\n",
    "\n",
    "**Target distribution:**\n",
    "\n",
    " -   Extrovert: 13,699 (~74%)\n",
    "\n",
    " -   Introvert: 4,825 (~26%)\n",
    "\n",
    " -  **Imbalanced target**, something I'll need to handle during training\n",
    "\n",
    "**Next Steps** (**Step 2** Plan: Clean the Data)\n",
    "\n",
    "I'll handle missing values carefully based on our EDA findings:\n",
    "\n",
    "1. Numerical Columns (float):\n",
    "\n",
    "    - Impute using correlated features, KNN Imputer.\n",
    "\n",
    "    - Use linear correlation-based fill when there's a strong relationship\n",
    "\n",
    "    - These include: Time_spent_Alone, Social_event_attendance, Going_outside, Friends_circle_size, Post_frequency\n",
    "\n",
    "2. Categorical Columns (object):\n",
    "\n",
    "    - For Stage_fear and Drained_after_socializing, I observed they correlate with missingness in numeric fields\n",
    "\n",
    "    - So I can fill them using related categorical/numeric values (like Going_outside, Post_frequency) grouped mode\n",
    "\n",
    "3. Outlier handling (optional but worth flagging for later â€” I might revisit this during model tuning).\n",
    "\n",
    "4. Encode categorical variables:\n",
    "\n",
    "    - Stage_fear, Drained_after_socializing, and Personality (target)\n",
    "\n",
    "5. Create a was_missing_* binary flag for imputed values\n",
    "\n",
    "    - Always a good idea as it gives models a shot at capturing patterns related to why data was missing.\n",
    "\n",
    "6. Save cleaned dataset for training reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988639cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add binary flags for each column with missing data\n",
    "missing_cols = [\n",
    "    'Time_spent_Alone',\n",
    "    'Stage_fear',\n",
    "    'Social_event_attendance',\n",
    "    'Going_outside',\n",
    "    'Drained_after_socializing',\n",
    "    'Friends_circle_size',\n",
    "    'Post_frequency'\n",
    "]\n",
    "\n",
    "for col in missing_cols:\n",
    "    train[f'{col}_missing'] = train[col].isna().astype(int)\n",
    "    test[f'{col}_missing'] = test[col].isna().astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39727f47",
   "metadata": {},
   "source": [
    "**Step 3: Fill Missing Values**\n",
    "\n",
    "- Numeric Columns -> KNN Imputer\n",
    "\n",
    "- Categorical Columns ->   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c091713",
   "metadata": {},
   "source": [
    "**Define Groups of Correlated Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d684bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logical groupings based on correlation structure\n",
    "group_social_behavior = ['Time_spent_Alone', 'Going_outside', 'Drained_after_socializing', 'Stage_fear']\n",
    "group_social_networking = ['Friends_circle_size', 'Post_frequency']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9dbd9",
   "metadata": {},
   "source": [
    "**KNN Imputer for Numerical Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9d3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Combine train and test for joint imputation (preserve indices to split later)\n",
    "combined = pd.concat([train, test], keys=['train', 'test'])\n",
    "\n",
    "# Use only the correlated numeric columns (drop categorical temporarily)\n",
    "knn_impute_cols = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside',\n",
    "                   'Friends_circle_size', 'Post_frequency']\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Only impute selected numeric columns\n",
    "combined[knn_impute_cols] = knn_imputer.fit_transform(combined[knn_impute_cols])\n",
    "\n",
    "# Split back\n",
    "train = combined.xs('train')\n",
    "test = combined.xs('test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eaea8e",
   "metadata": {},
   "source": [
    "**Predict Categorical Columns (Binary Classification)**\n",
    "\n",
    "But first, before we forget again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c98d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean string-based binary columns while keeping NaNs intact\n",
    "binary_map = {'Yes': 1, 'No': 0}\n",
    "for col in ['Stage_fear', 'Drained_after_socializing']:\n",
    "    train.loc[:, col] = train[col].apply(lambda x: binary_map[x] if x in binary_map else np.nan)\n",
    "    test.loc[:, col] = test[col].apply(lambda x: binary_map[x] if x in binary_map else np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06299a87",
   "metadata": {},
   "source": [
    "I'll predict missing values in `Stage_fear` and `Drained_after_socializing` by using logistic regression trained only on the rows with complete values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e1bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def impute_categorical(train_df, test_df, column, predictors):\n",
    "    # Only use rows with known target\n",
    "    known = train_df[train_df[column].notnull()]\n",
    "    unknown = train_df[train_df[column].isnull()]\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(known[predictors], known[column].astype(int))\n",
    "\n",
    "    # Predict and fill missing values in train\n",
    "    train_df.loc[train_df[column].isnull(), column] = model.predict(unknown[predictors])\n",
    "\n",
    "    # Predict and fill missing values in test\n",
    "    test_df.loc[test_df[column].isnull(), column] = model.predict(test_df.loc[test_df[column].isnull(), predictors])\n",
    "\n",
    "# Define predictor sets based on correlation analysis\n",
    "predictors_stage_fear = ['Time_spent_Alone', 'Going_outside', 'Social_event_attendance']\n",
    "predictors_drained = ['Time_spent_Alone', 'Stage_fear', 'Going_outside']\n",
    "\n",
    "impute_categorical(train, test, 'Stage_fear', predictors_stage_fear)\n",
    "impute_categorical(train, test, 'Drained_after_socializing', predictors_drained)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb916a5",
   "metadata": {},
   "source": [
    "Let's take a moment to validate our janitorial efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "908afd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train:\n",
      " id                                   0\n",
      "Time_spent_Alone                     0\n",
      "Stage_fear                           0\n",
      "Social_event_attendance              0\n",
      "Going_outside                        0\n",
      "Drained_after_socializing            0\n",
      "Friends_circle_size                  0\n",
      "Post_frequency                       0\n",
      "Personality                          0\n",
      "Time_spent_Alone_missing             0\n",
      "Stage_fear_missing                   0\n",
      "Social_event_attendance_missing      0\n",
      "Going_outside_missing                0\n",
      "Drained_after_socializing_missing    0\n",
      "Friends_circle_size_missing          0\n",
      "Post_frequency_missing               0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test:\n",
      " id                                      0\n",
      "Time_spent_Alone                        0\n",
      "Stage_fear                              0\n",
      "Social_event_attendance                 0\n",
      "Going_outside                           0\n",
      "Drained_after_socializing               0\n",
      "Friends_circle_size                     0\n",
      "Post_frequency                          0\n",
      "Personality                          6175\n",
      "Time_spent_Alone_missing                0\n",
      "Stage_fear_missing                      0\n",
      "Social_event_attendance_missing         0\n",
      "Going_outside_missing                   0\n",
      "Drained_after_socializing_missing       0\n",
      "Friends_circle_size_missing             0\n",
      "Post_frequency_missing                  0\n",
      "dtype: int64\n",
      "\n",
      "Stage_fear unique: [0.0 1.0]\n",
      "Drained_after_socializing unique: [0.0 1]\n",
      "Personality unique: ['Extrovert' 'Introvert']\n",
      "\n",
      "Target value counts:\n",
      "Personality\n",
      "Extrovert    13699\n",
      "Introvert     4825\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train sample:\n",
      "   id  Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
      "0   0               0.0        0.0                      6.0            4.0   \n",
      "1   1               1.0        0.0                      7.0            3.0   \n",
      "2   2               6.0        1.0                      1.0            0.0   \n",
      "3   3               3.0        0.0                      7.0            3.0   \n",
      "4   4               1.0        0.0                      4.0            4.0   \n",
      "\n",
      "  Drained_after_socializing  Friends_circle_size  Post_frequency Personality  \\\n",
      "0                       0.0                 15.0             5.0   Extrovert   \n",
      "1                       0.0                 10.0             8.0   Extrovert   \n",
      "2                         1                  3.0             0.0   Introvert   \n",
      "3                       0.0                 11.0             5.0   Extrovert   \n",
      "4                       0.0                 13.0             6.0   Extrovert   \n",
      "\n",
      "   Time_spent_Alone_missing  Stage_fear_missing  \\\n",
      "0                         0                   0   \n",
      "1                         0                   0   \n",
      "2                         0                   0   \n",
      "3                         0                   0   \n",
      "4                         0                   0   \n",
      "\n",
      "   Social_event_attendance_missing  Going_outside_missing  \\\n",
      "0                                0                      0   \n",
      "1                                0                      0   \n",
      "2                                0                      0   \n",
      "3                                0                      0   \n",
      "4                                0                      0   \n",
      "\n",
      "   Drained_after_socializing_missing  Friends_circle_size_missing  \\\n",
      "0                                  0                            0   \n",
      "1                                  0                            0   \n",
      "2                                  1                            0   \n",
      "3                                  0                            0   \n",
      "4                                  0                            0   \n",
      "\n",
      "   Post_frequency_missing  \n",
      "0                       0  \n",
      "1                       0  \n",
      "2                       0  \n",
      "3                       0  \n",
      "4                       1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18524 entries, 0 to 18523\n",
      "Data columns (total 16 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   id                                 18524 non-null  int64  \n",
      " 1   Time_spent_Alone                   18524 non-null  float64\n",
      " 2   Stage_fear                         18524 non-null  object \n",
      " 3   Social_event_attendance            18524 non-null  float64\n",
      " 4   Going_outside                      18524 non-null  float64\n",
      " 5   Drained_after_socializing          18524 non-null  object \n",
      " 6   Friends_circle_size                18524 non-null  float64\n",
      " 7   Post_frequency                     18524 non-null  float64\n",
      " 8   Personality                        18524 non-null  object \n",
      " 9   Time_spent_Alone_missing           18524 non-null  int64  \n",
      " 10  Stage_fear_missing                 18524 non-null  int64  \n",
      " 11  Social_event_attendance_missing    18524 non-null  int64  \n",
      " 12  Going_outside_missing              18524 non-null  int64  \n",
      " 13  Drained_after_socializing_missing  18524 non-null  int64  \n",
      " 14  Friends_circle_size_missing        18524 non-null  int64  \n",
      " 15  Post_frequency_missing             18524 non-null  int64  \n",
      "dtypes: float64(5), int64(8), object(3)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1. Confirm no missing values\n",
    "print(\"Missing values in train:\\n\", train.isna().sum())\n",
    "print(\"\\nMissing values in test:\\n\", test.isna().sum())\n",
    "\n",
    "# 2. Check dtypes and unique values of categorical (now numeric) columns\n",
    "print(\"\\nStage_fear unique:\", train['Stage_fear'].unique())\n",
    "print(\"Drained_after_socializing unique:\", train['Drained_after_socializing'].unique())\n",
    "print(\"Personality unique:\", train['Personality'].unique())\n",
    "\n",
    "# 3. Check target distribution\n",
    "print(\"\\nTarget value counts:\")\n",
    "print(train['Personality'].value_counts())\n",
    "\n",
    "# 4. Sample preview\n",
    "print(\"\\nTrain sample:\")\n",
    "print(train.head())\n",
    "\n",
    "# Show columns and data types\n",
    "train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f8366",
   "metadata": {},
   "source": [
    "- spotless\n",
    "\n",
    "---\n",
    "\n",
    "Fix label formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae89bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18524 entries, 0 to 18523\n",
      "Data columns (total 16 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   id                                 18524 non-null  int64  \n",
      " 1   Time_spent_Alone                   18524 non-null  float64\n",
      " 2   Stage_fear                         18524 non-null  int64  \n",
      " 3   Social_event_attendance            18524 non-null  float64\n",
      " 4   Going_outside                      18524 non-null  float64\n",
      " 5   Drained_after_socializing          18524 non-null  int64  \n",
      " 6   Friends_circle_size                18524 non-null  float64\n",
      " 7   Post_frequency                     18524 non-null  float64\n",
      " 8   Personality                        18524 non-null  int64  \n",
      " 9   Time_spent_Alone_missing           18524 non-null  int64  \n",
      " 10  Stage_fear_missing                 18524 non-null  int64  \n",
      " 11  Social_event_attendance_missing    18524 non-null  int64  \n",
      " 12  Going_outside_missing              18524 non-null  int64  \n",
      " 13  Drained_after_socializing_missing  18524 non-null  int64  \n",
      " 14  Friends_circle_size_missing        18524 non-null  int64  \n",
      " 15  Post_frequency_missing             18524 non-null  int64  \n",
      "dtypes: float64(5), int64(11)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "train = train.copy()\n",
    "test = test.copy()\n",
    "\n",
    "# Convert to int\n",
    "train['Drained_after_socializing'] = train['Drained_after_socializing'].astype(int)\n",
    "test['Drained_after_socializing'] = test['Drained_after_socializing'].astype(int)\n",
    "\n",
    "train['Stage_fear'] = train['Stage_fear'].astype(int)\n",
    "test['Stage_fear'] = test['Stage_fear'].astype(int)\n",
    "\n",
    "# Encode labels\n",
    "label_map = {'Introvert': 0, 'Extrovert': 1}\n",
    "train['Personality'] = train['Personality'].map(label_map)\n",
    "test['Personality'] = test['Personality'].map(label_map)\n",
    "\n",
    "# Show columns and data types\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned datasets\n",
    "train.to_csv(\"../data/cleaned_train.csv\", index=False)\n",
    "test.to_csv(\"../data/cleaned_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a44bc6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Split the Training Set\n",
    "\n",
    "- `X_train`, `X_valid`\n",
    "\n",
    "- `y_train`, `y_valid`\n",
    "\n",
    "For model evaluation before final test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31fe19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['Personality', 'id'])  # keep ID only for post-pred join\n",
    "y = train['Personality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0125a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    'Time_spent_Alone', 'Social_event_attendance', 'Going_outside',\n",
    "    'Friends_circle_size', 'Post_frequency'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09a0db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[num_cols] = scaler.fit_transform(X[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3f2eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled['Alone_x_Fear'] = X_scaled['Time_spent_Alone'] * X_scaled['Stage_fear']\n",
    "X_scaled['Social_x_Drained'] = X_scaled['Social_event_attendance'] * X_scaled['Drained_after_socializing']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebee665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5b4f2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       965\n",
      "           1       0.97      0.98      0.98      2740\n",
      "\n",
      "    accuracy                           0.96      3705\n",
      "   macro avg       0.96      0.95      0.95      3705\n",
      "weighted avg       0.96      0.96      0.96      3705\n",
      "\n",
      "AUC: 0.9547861276048561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_val, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f5c52",
   "metadata": {},
   "source": [
    "Holy Crap! 95%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
